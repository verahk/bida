---
title: "toy_example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{toy_example}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  results = "hold"
)
```



Here we apply BIDA on data simulated from an small DAG with 4 nodes. 
In the associated CPDAG, the edge between $X_1$ and $X_2$ is undirected.
Hence, the effect of $X_1$ on $X_2$ and $X_3$ can not be uniquely identified.


```{r, fig.show="hold", out.width="45%"}
library(bida)
library(pcalg)

# load example network
bn <- example_networks("illustrate_posterior")  # bn.fit.dnet-object
g <- as(bnlearn::amat(bn), "graphNEL")
Rgraphviz::plot(g, main = "DAG")
Rgraphviz::plot(pcalg::dag2cpdag(g), main = "CPDAG")
```

To sample from the network, we apply the `bida::sample_data_from_bn` function. The function is a wrapper around `bnlearn::rbn`, that re-samples data sets until at least 2 levels of every variable is observed (required for `BiDAG::partitionMCMC`). 
```{r}
data <- bida:::sample_data_from_bn(bn, 1000)
nlev <- apply(data, 2, max) +1
```

### Sample DAGs
To apply BIDA, the first step is to compute the posterior support over adjustment sets.
To this end, we first sample a chain of graphs from the approximate posterior distribution using the partitionMCMC-algorithm implied in `BiDAG::partitionMCMC`. 
```{r, cache  = TRUE}
# specify a uniform prior over DAGs 
my_score <- BiDAG::scoreparameters(scoretype = "bdecat", 
                                   data.frame(data),
                                   bdecatpar = list(chi=1,edgepf=1))
fit <- BiDAG::partitionMCMC(scorepar = my_score, startspace = NULL)
dags <- fit$traceadd$incidence
```


### Apply BIDA-method
Given a sample of DAGs and a class of backdoor adjustment sets, we apply`bida:::bida_sample` to estimate the posterior over the intervention distributions for each cause-effect pair.
This function identifies and computes the support over the unique adjustment sets in the sample of DAGs and, subsequently, computes the posterior over intervention distribution through the backdoor formula.
```{r}
fit  <- bida_sample(data, dags, type = "categorical", adjset = "pa") 
```


### Sampling from the posterior distribution
Samples from the posterior distribution is obtained through Monte Carlo sampling.
Here are samples for the interventional CPT $P(X_2 = 1|do(X_1))$ for each of the two possible interventions on $X_1$. 
```{r, fig.show="hold", out.width="45%"}
smpl <- posterior_sample(fit[[1, 2]], n = 10**3)

for (k in seq_len(nlev[1]))  {
  hist(smpl[k, 1, ], freq = F, xlim = c(0, 1),
       xlab = sprintf("P(X2|do(X1 = %s))", k-1),
       main = "")
  lines(density(smpl[k, 1, ]),  col = k)
}
```

The two modes of the distributions reflects that the underlying DAG can not be uniquely identified. 

To summarize the strength of the causal relationship between variables into a single quantity, what we refer to as the "causal effect", we contrast the intervention distributions associated with each cause-effect pair by the Jensen-Shannon-divergence (JSD). The JSD is a measure of the distance between intervention distributions. The stronger the causal influence of $X_i$ on a variable $X_j$, the more the distribution of $X_j$ varies under different interventions on $X_i$, and the greater the JSD. 

Here we show posterior distribution of the causal effects of $X_1$ on each of the remaining variables, obtained by applying the JSD to posterior samples of the associated intervention distributions.
```{r, fig.show="hold", out.width="50%"}
for (j in 2:4) {
  tau <- posterior_sample(fit[[1, j]], 10**3, ace_funs = list(jsd = bida:::avg_jsd_array))
  xlab <- bquote("causal effect,"~pi[1][.(as.numeric(j))])
  hist(tau, freq = F, xlim = c(0, log(2)),
       #xlab = sprintf("causal effect, P(X_%s|do(X_%s)))"),
       xlab = xlab,
       main = "")
  lines(density(tau), col = j)
}
```


### Posterior mean
The posterior mean of intervention distributions can be computed analytically throught the backdoor formula, given the approximated posterior over adjustment sets. 

```{r}
pmean <- posterior_mean(fit)
pmean[1, ]
```

The posterior mean of the causal effect, the transformed intervention CPTs, are approximated by Monte Carlo sampling.
```{r}
posterior_mean(fit, ace_funs = list(jsd = bida:::avg_jsd_array))
```
