---
title: "test_optimize_partition"
author: "Vera Kvisgaard"
date: "2024-05-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      results = "hold")
```

```{r, results = "hide"}
library(pcalg) # for as(adjmat, "graphNEL")
library(bida)
here::i_am("./inst/vignettes/optimize_partition.Rmd")
```

## Test optmization routines
Write a routine that, for a given frequency table, compares the partitions and local scores resulting from each optimization routine `methods = c("tree", "ldag", "part")`.
```{r}
tester <- function(counts, levels, methods = c("tree", "ldag", "part"), regular = F) {
  df <- cbind(expand.grid(levels), n = counts)
  scores <- setNames(numeric(length(methods)), methods)
  for (method in methods) {
    res <- optimize_partition(counts, levels, ess = 1, method, regular = regular)
    df[[method]] <- get_parts(res$partition)
    scores[method] <- sum(res$scores)
  }
  df[["none"]] <- seq_len(nrow(counts))
  scores["none"] <- sum(bida:::famscore_bdeu_byrow(counts, 1, ncol(counts), nrow(counts), s = 1))
  return(list(df, scores))
}
```


### Binary split
Compare partitions for a frequency table with a binary split of the outcome space, where the outcome variable is independent of one variable:
```{r}
levels <- rep(list(0:1), 2)
counts <- cbind(10, c(10, 10, 100, 100))
tester(counts, levels)
```
### V-structure
Compare partitions given a frequency table corresponding to a v-structure with labels on both parents.
```{r}
levels <- rep(list(0:1), 2)
counts <- cbind(10, c(10, 100, 100, 100))
tester(counts, levels)
```
The `tree`-partition returns only one region, i.e. the no-parent CPT, as the score is not improved by splitting on any of the parent variables for the given frequency table. 
```{r}
cat("Score, P(Y|X1, X2):")
sum(bida:::famscore_bdeu_byrow(counts, ess = 1, r = 2, q = 4, s = 1))
cat("Score, P(Y|X2):")
sum(bida:::famscore_bdeu_byrow(rowsum(counts, c(1, 1, 2, 2)), ess = 1, r = 2, q = 4, s = c(2, 2)))
cat("Score P(Y):")
sum(bida:::famscore_bdeu_byrow(matrix(colSums(counts), 1), ess = 1, r = 2, q = 4, s = 4))
```

In the following example, also the `tree` procedure captures the correct local structure.
```{r}
levels <- rep(list(0:1), 2)
counts <- cbind(c(100, 10, 10, 10), c(10, 100, 100, 100))
tester(counts, levels, regular = F)
```

The `regular` option of the `optimize_partition` function forces a partition that do not implicitly encode any conditional independencies.
```{r}
tester(counts, levels, regular = T)
```



```{r}



```



```{r}

# import labeled DAG
bn   <- readRDS(here::here("./data/LDAG10.rds"))
bn   <- readRDS(here::here("./data/child.rds"))
dag  <- bnlearn::amat(bn)
probs <- lapply(bn, "[[", "prob")

# extract levels and partitions from distribution - to draw random distribution over labeled DAG
nlev <- sapply(probs, function(x) dim(x)[1])
levels <- lapply(nlev-1, seq.int, from = 0)
partitions <- lapply(probs, partition_from_cpt_array)

par <- list(node = seq_along(bn), 
            N = round(10**seq(2, 4, length.out = 50)))
res <- array(list(), lengths(par), par)
for (N in par$N) {
  
  #bn <- rand_bn(dag, "cat", alpha = 1, nlev = nlev, partitions = partitions)
  data <- sample_data_from_bn(bn, N)
  
  for (j in seq_along(bn)) {
    #parentnodes <- which(dag[, j] == 1)
    parentnodes <- match(bn[[j]]$parents, names(bn))
    # compute BDeu-params for full CPT 
    fit <- bida_bdeu(data, j, parentnodes, ess = 1, nlev = nlev)
    
    # list params for CPTs with different local-structure
    fits <- list() 
    fits$none <- fit
    if (length(parentnodes) > 1) {
      # optimize partition of parent outcomes
      for (method in c("tree", "ldag")) {
        tmp <- optimize_bdeu(fit, method = method, regular = F)
        fits[[method]] <- replace(fit, "partition", list(tmp$partition))
      }
    }
    
    # evaluate fitted parameters
    dimnames <- list(method = names(fits),
                     variable = c("score", "mse", letters[1:4]))
    eval <- array(NA, lengths(dimnames), dimnames)
    for (i in seq_along(fits)) {
      fit   <- fits[[i]]
      eval[i, "score"] <- score_bdeu(fit) 
      eval[i, "mse"]  <- mean((mean_bdeu(fit, reduced = FALSE)-bn[[j]]$prob)**2)
      if (is.null(fit$partition)) next 
      comemb <- partition_confusion_matrix(get_parts(fit$partition), get_parts(partitions[[j]]))
      eval[i, 3:6] <- comemb/sum(comemb)
    }
    
    res[[paste(j), paste(N)]] <- eval
  }
}

```




```{r}
library(ggplot2)

df <- expand.grid(dimnames(res), stringsAsFactors = FALSE)
df$N <- as.numeric(df$N)

tmp <- do.call(rbind, res)
indx <- rep.int(seq_len(nrow(df)), vapply(res, nrow, integer(1)))
df  <- cbind(df[indx, ], local_struct = rownames(tmp), tmp)

# plot score 
ggplot(df, aes(N, -score, color = local_struct, group = local_struct)) +
  facet_wrap(node~., scales = "free") +
  geom_point() + 
  geom_line() +
  scale_y_log10()

ggplot(df, aes(N, mse, color = local_struct, group = local_struct)) +
  facet_wrap(node~., scales = "free") +
  geom_line() +
  scale_y_log10() +
  scale_x_log10()


tmp <- tidyr:::pivot_longer(df, letters[1:4])
tmp <- dplyr::filter(tmp, !local_struct == "none")
ggplot(tmp, aes(N, value, color = name, fill = name)) +
  facet_grid(node~local_struct, scales = "free") +
  geom_area() +
  scale_x_log10()

```
